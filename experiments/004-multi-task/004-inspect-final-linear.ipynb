{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting final linear projection\n",
    "\n",
    "I'd like to get a better sense of \"how much of the space\" is being accessed by each linear projection to each of the two outputs. Essentially I'd like to understand the equivalent of how many neurons are being used for each task, but the more general form when considering rotated output spaces. I'm not sure if this even makes sense as a question to ask, but I'd still like to see.\n",
    "\n",
    "I'd expect:\n",
    "- both projections to access a similar \"amount\" of space\n",
    "- to understand more about any remaining redundancy in the network from how much space might be \"left\" after considering the two projection vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from physics_mi.utils import set_all_seeds\n",
    "\n",
    "RESULTS = Path(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2542658879\n"
     ]
    }
   ],
   "source": [
    "seed = np.random.randint(1, 2**32 - 1)\n",
    "# seed = 689334534\n",
    "set_all_seeds(seed)\n",
    "print(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, use_act=True, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        if use_act:\n",
    "            self.act = nn.ReLU()\n",
    "        self.use_act = use_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_act:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=16, output_dim=2, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = nn.Sequential(\n",
    "            LinearLayer(input_dim, hidden_dim, use_act=True),\n",
    "            LinearLayer(hidden_dim, output_dim, use_act=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1e6cf946cb48caa0246f73c526c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fps = list(RESULTS.glob(\"*.pkl\"))\n",
    "\n",
    "rows = []\n",
    "for fp in tqdm(fps):\n",
    "    with open(fp, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    rows.append(data)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df[\"valid_loss\"] = df[\"valid_loss\"].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>outputs</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.), tenso...</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(-0.1858), ...</td>\n",
       "      <td>1080586112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000664</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.), tenso...</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.0037), t...</td>\n",
       "      <td>825201060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.), tenso...</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(-0.4611), ...</td>\n",
       "      <td>500382378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.), tenso...</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(-0.2236), ...</td>\n",
       "      <td>340316710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.), tenso...</td>\n",
       "      <td>{'layers.0.linear.weight': [[tensor(0.2780), t...</td>\n",
       "      <td>337361766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valid_loss                                            outputs  \\\n",
       "0    0.000400  {'layers.0.linear.weight': [[tensor(0.), tenso...   \n",
       "1    0.000664  {'layers.0.linear.weight': [[tensor(0.), tenso...   \n",
       "2    0.000276  {'layers.0.linear.weight': [[tensor(0.), tenso...   \n",
       "3    0.000242  {'layers.0.linear.weight': [[tensor(0.), tenso...   \n",
       "4    0.000163  {'layers.0.linear.weight': [[tensor(0.), tenso...   \n",
       "\n",
       "                                               model        seed  \n",
       "0  {'layers.0.linear.weight': [[tensor(-0.1858), ...  1080586112  \n",
       "1  {'layers.0.linear.weight': [[tensor(0.0037), t...   825201060  \n",
       "2  {'layers.0.linear.weight': [[tensor(-0.4611), ...   500382378  \n",
       "3  {'layers.0.linear.weight': [[tensor(-0.2236), ...   340316710  \n",
       "4  {'layers.0.linear.weight': [[tensor(0.2780), t...   337361766  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([142, 2, 16])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lws = [row[\"model\"][\"layers.1.linear.weight\"] for _, row in df.iterrows()]\n",
    "lws = torch.stack(lws)\n",
    "lws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2728, 1.0186],\n",
       "         [1.3493, 1.2235],\n",
       "         [1.1754, 1.0827],\n",
       "         [1.2027, 0.9973],\n",
       "         [1.3525, 1.1315],\n",
       "         [1.2881, 1.1579],\n",
       "         [1.2033, 1.0430],\n",
       "         [1.3475, 1.0578],\n",
       "         [1.3293, 1.0682],\n",
       "         [1.3438, 1.2283]]),\n",
       " tensor([[[-1.1063e-01,  2.3505e-01],\n",
       "          [-7.6833e-02, -5.0185e-01],\n",
       "          [-6.9651e-02, -3.0779e-01],\n",
       "          [ 7.0652e-02, -3.9195e-02],\n",
       "          [ 2.2668e-02, -9.5302e-02],\n",
       "          [-7.3147e-02, -1.6435e-01],\n",
       "          [-4.3449e-01, -3.8562e-01],\n",
       "          [ 1.7947e-01,  4.3112e-02],\n",
       "          [-5.3740e-02, -4.9188e-05],\n",
       "          [ 5.1346e-01, -1.3242e-01],\n",
       "          [ 7.2959e-02,  4.6588e-01],\n",
       "          [ 4.8564e-01, -6.9546e-02],\n",
       "          [ 2.6752e-01, -3.9593e-01],\n",
       "          [-3.9039e-01,  1.0043e-01],\n",
       "          [ 1.1560e-01, -2.4645e-02],\n",
       "          [-1.1111e-02,  5.5729e-02]]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svds = [torch.svd(lw.T) for lw in lws]\n",
    "svs = torch.stack([svd.S for svd in svds])\n",
    "basis_vectors = torch.stack([svd.U[:, :2] for svd in svds])\n",
    "svs[:10], us[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7760, 0.5603],\n",
       "        [0.6498, 0.4818],\n",
       "        [0.5857, 0.4428],\n",
       "        [0.6485, 0.4690],\n",
       "        [0.6013, 0.4003],\n",
       "        [0.6506, 0.5790],\n",
       "        [0.7648, 0.4794],\n",
       "        [0.6458, 0.5749],\n",
       "        [0.6447, 0.4706],\n",
       "        [0.5500, 0.5343]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svs = torch.stack([torch.svd(Net().state_dict()[\"layers.1.linear.weight\"]).S for lw in lws])\n",
    "svs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure what more I'm going to be able to tell here aside from the fact that the singular values are higher than a randomly initialised weight matrix, and generally quite similar in value between each dimension suggesting that the relevant features are being scaled roughly equally (as one might expect from independent tasks) and are useful for the task. I realise don't know if this is telling me much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physics-mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
