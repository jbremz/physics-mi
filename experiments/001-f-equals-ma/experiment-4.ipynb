{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `F = ma` - with activation - extra layer\n",
    "\n",
    "Some 3D funcs that were useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Keeping this extremely simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, use_act=True, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.act = nn.ReLU()\n",
    "        self.use_act = use_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_act:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, use_act=True, dim=32, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = nn.Sequential(LinearLayer(2, dim, use_act=use_act), LinearLayer(dim, 1, use_act=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Going to sample $x_1$ (mass) and $x_2$ (acceleration) such that their product is uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.5\n",
    "\n",
    "Y = torch.rand(10000)\n",
    "X = torch.empty(10000, 2)\n",
    "X[:, 0] = Y / (torch.rand(10000) * (1 - eps) + eps)\n",
    "X[:, 1] = Y / X[:, 0]\n",
    "\n",
    "# need to randomly swap x1 and x2 so that they're identically distributed - can do this because their product is commutative\n",
    "mask = torch.rand(10000) < 0.5\n",
    "swap_vals = X[:, 0][mask]\n",
    "X[:, 0][mask] = X[:, 1][mask]\n",
    "X[:, 1][mask] = swap_vals\n",
    "\n",
    "assert torch.allclose(X[:, 0] * X[:, 1], Y)\n",
    "\n",
    "Y = Y[:, None]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(X[:, 0], alpha=0.5, density=True, label=\"mass\")\n",
    "ax.hist(X[:, 1], alpha=0.5, density=True, label=\"acceleration\")\n",
    "ax.hist(Y[:, 0], alpha=0.5, density=True, label=\"force\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_inds = np.random.permutation(range(X.shape[0]))  # shuffled indices\n",
    "\n",
    "X_train = X[s_inds[:8000]]\n",
    "Y_train = Y[s_inds[:8000]]\n",
    "X_valid = X[s_inds[8000:]]\n",
    "Y_valid = Y[s_inds[8000:]]\n",
    "\n",
    "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "I'll just do full gradient descent to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000  # number of epochs\n",
    "\n",
    "model = Net(use_act=True, dim=2)\n",
    "loss_func = nn.MSELoss()\n",
    "optimiser = Adam(model.parameters(), lr=1e-3)\n",
    "log = []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    log_sample = {}\n",
    "\n",
    "    # Training update\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    Y_hat = model(X_train)\n",
    "    loss = loss_func(Y_hat, Y_train)\n",
    "    log_sample[\"train_loss\"] = float(loss.detach())\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    # Validation set\n",
    "    model.eval()\n",
    "    Y_hat = model(X_valid)\n",
    "    loss = loss_func(Y_hat, Y_valid)\n",
    "    log_sample[\"valid_loss\"] = float(loss.detach())\n",
    "\n",
    "    log.append(log_sample)\n",
    "\n",
    "df = pd.DataFrame(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, valid_loss):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_loss, label=\"train\")\n",
    "    ax.plot(valid_loss, label=\"valid\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def get_preds(model):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = model(X_valid)\n",
    "\n",
    "    y_preds = out.flatten().numpy()\n",
    "    y_targs = Y_valid.flatten().numpy()\n",
    "\n",
    "    return y_preds, y_targs\n",
    "\n",
    "\n",
    "def get_valid_loss(model, loss_func):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = model(X_valid)\n",
    "\n",
    "    return loss_func(out, Y_valid)\n",
    "\n",
    "\n",
    "def plot_results(y_preds, y_targs):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(y_preds, y_targs, s=4, label=\"predictions\")\n",
    "    ax.plot(y_targs, y_targs, color=\"salmon\", ls=\"--\", lw=0.5, label=\"perfect accuracy\")\n",
    "    ax.set(xlabel=\"y_preds\", ylabel=\"y_targs\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(df[\"train_loss\"], df[\"valid_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_targs = get_preds(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valid_loss(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(y_preds, y_targs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, \"\\n\", param.data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect intermediate values\n",
    "\n",
    "Going to go operation by operation to see if I can see what's going on.\n",
    "\n",
    "input ($\\rightarrow$ prebias_preacts $\\rightarrow$ preacts $\\rightarrow$ acts) ($\\rightarrow$ prebias $\\rightarrow$ output)\n",
    "\n",
    "(with the layers grouped in brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_breakdown(x1, x2, print_steps=True, return_steps=False):\n",
    "    x1, x2 = float(x1), float(x2)\n",
    "\n",
    "    x = torch.tensor([[x1, x2]]).T\n",
    "    prebias_preacts = torch.matmul(SD[\"layers.0.linear.weight\"], x)\n",
    "    preacts = prebias_preacts[:, 0] + SD[\"layers.0.linear.bias\"]\n",
    "    acts = torch.nn.functional.relu(preacts)\n",
    "    prebias = torch.matmul(SD[\"layers.1.linear.weight\"], acts)\n",
    "    output = prebias + SD[\"layers.1.linear.bias\"]\n",
    "\n",
    "    if print_steps:\n",
    "        print(\"Input:\", \"\\n\", x, \"\\n\")\n",
    "\n",
    "        print(\"================ Layer 0 ================\", \"\\n\")\n",
    "        print(\"Weight:\", \"\\n\", SD[\"layers.0.linear.weight\"], \"\\n\")\n",
    "        print(\"Result:\", \"\\n\", prebias_preacts, \"\\n\")\n",
    "        print(\"Bias:\", \"\\n\", SD[\"layers.0.linear.bias\"], \"\\n\")\n",
    "        print(\"Result:\", \"\\n\", preacts, \"\\n\")\n",
    "        print(\"Activations:\", \"\\n\", acts, \"\\n\")\n",
    "\n",
    "        print(\"================ Layer 1 ================\", \"\\n\")\n",
    "        print(\"Weight:\", \"\\n\", SD[\"layers.1.linear.weight\"], \"\\n\")\n",
    "        print(\"Result:\", \"\\n\", prebias, \"\\n\")\n",
    "        print(\"Bias:\", \"\\n\", SD[\"layers.1.linear.bias\"], \"\\n\")\n",
    "        print(\"Output:\", \"\\n\", output, \"\\n\")\n",
    "\n",
    "        print(f\"y_true = {x1*x2:.3f}\")\n",
    "\n",
    "    if return_steps:\n",
    "        return prebias_preacts, preacts, acts, prebias, output\n",
    "    \n",
    "def plot_model_breakdown(x1, x2, ax=None, legend=True, scatter=True):\n",
    "    %matplotlib ipympl\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "    input = (x1, x2)\n",
    "\n",
    "    prebias_preacts, preacts, acts, prebias, output = model_breakdown(*input, print_steps=False, return_steps=True)\n",
    "\n",
    "    x = [[input[0], input[1], 0], prebias_preacts.flatten().tolist(), preacts.flatten().tolist(), acts.flatten().tolist(), [float(prebias),0,0], [float(output),0,0]]\n",
    "    x = np.asarray(x)\n",
    "\n",
    "    # Plot the surface\n",
    "    # ax.plot_surface(X, Y, Z, cmap=\"viridis\", edgecolor=\"none\")\n",
    "    ax.scatter(*x[0], alpha=1.0, label='input', color='mediumseagreen')\n",
    "    if scatter:\n",
    "        ax.scatter(*x[1], marker='x', alpha=1.0, label='prebias_preacts', color='darkgray')\n",
    "        ax.scatter(*x[2], marker='x', alpha=1.0, label='preacts', color='mediumpurple')\n",
    "        ax.scatter(*x[3], marker='x', alpha=1.0, label='acts', color='turquoise')\n",
    "        ax.scatter(*x[4], marker='x', alpha=1.0, label='prebias', color='hotpink')\n",
    "    ax.scatter(*x[5], marker='x', alpha=1.0, label='output', color='lightcoral')\n",
    "\n",
    "    ax.plot(*x.T, lw=0.5)\n",
    "    ax.set(xlabel='component 0', ylabel='component 1', zlabel='component 2')\n",
    "    if legend:\n",
    "        ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_breakdown(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "N = 2\n",
    "pairs = np.concatenate(np.stack(np.meshgrid(np.linspace(0, 1, N), np.linspace(0, 1, N))).T)\n",
    "\n",
    "plot_model_breakdown(*pairs[0], ax, scatter=False)\n",
    "for pair in pairs[1:]:\n",
    "    plot_model_breakdown(*pair, ax, legend=False, scatter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a very interpretable diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = model.state_dict()\n",
    "weight = SD[\"layers.0.linear.weight\"].numpy()\n",
    "bias = SD[\"layers.0.linear.bias\"].numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sc = ax.scatter(*weight.T, c=bias, cmap=\"coolwarm\")\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(sc, ax=ax, label=\"bias\")\n",
    "\n",
    "ax.set(xlabel=\"Component 0\", ylabel=\"Component 1\")\n",
    "\n",
    "ax.axvline(0, color=\"k\", linestyle=\"--\", linewidth=0.5)\n",
    "ax.axhline(0, color=\"k\", linestyle=\"--\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How's this actually going to _transform_ the input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_range(x2=0.5):\n",
    "    # True solution\n",
    "    x1 = np.linspace(0, 1, 50)\n",
    "    x2 = np.repeat(x2, 50)\n",
    "    y = x1 * x2\n",
    "\n",
    "    # Predicted solution\n",
    "    with torch.inference_mode():\n",
    "        x = torch.stack([torch.as_tensor(x1), torch.as_tensor(x2)]).T.float()\n",
    "        y_hat = model(x)\n",
    "        y_hat = y_hat.detach().numpy()\n",
    "\n",
    "    return y_hat, y\n",
    "\n",
    "\n",
    "def get_preds_multi_range():\n",
    "    x2s = np.linspace(0, 1, 11)\n",
    "    rows = []\n",
    "    for x2 in x2s:\n",
    "        row = {\"x2\": x2}\n",
    "        row[\"y_hat\"], row[\"y\"] = get_preds_range(x2=x2)\n",
    "        rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_preds_multi_range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing $x_2$ and varying $x_1$ to isolate behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for row in results:\n",
    "    ax.plot(row[\"y_hat\"], row[\"y\"], lw=1, label=f\"x2 = {row['x2']:.2f}\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], color=\"salmon\", lw=2, ls=\"--\", label=\"perfect accuracy\")\n",
    "ax.set(xlabel=\"y_preds\", ylabel=\"y_targs\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physics-mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
