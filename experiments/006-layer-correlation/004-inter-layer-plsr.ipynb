{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interlayer PLSR\n",
    "\n",
    "The plan:\n",
    "1. get multi-layer activations for validation set\n",
    "1. get multi-layer activations for task datasets\n",
    "1. calculate PCs from valid_acts for both layers\n",
    "1. use the PCs from layer1 as our dependent variable and the activation space of layer0 as our multivariate input independent variable and perform PLSR\n",
    "1. take the resulting layer0 PLSR components and see how they overlap with PC components from layer0\n",
    "1. maybe we can produce some groupings of the layer0 PCs from this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from physics_mi.utils import set_all_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(1, 2**32 - 1)\n",
    "# seed = 1922977544\n",
    "set_all_seeds(seed)\n",
    "print(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Keeping this extremely simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, use_act=True, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        if use_act:\n",
    "            self.act = nn.ReLU()\n",
    "        self.use_act = use_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_act:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim=4, hidden_dim=16, output_dim=2, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = nn.Sequential(\n",
    "            LinearLayer(input_dim, hidden_dim, use_act=True),\n",
    "            LinearLayer(hidden_dim, hidden_dim, use_act=True),\n",
    "            LinearLayer(hidden_dim, output_dim, use_act=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 10000\n",
    "\n",
    "# Epsilon value\n",
    "eps = 0.5\n",
    "\n",
    "\n",
    "# Generate Y values\n",
    "def generate_Y(n_samples):\n",
    "    return torch.rand(n_samples)\n",
    "\n",
    "\n",
    "# Generate X values based on Y\n",
    "def generate_X(Y, eps):\n",
    "    X = torch.empty(len(Y), 2)\n",
    "    X[:, 0] = Y / (torch.rand(len(Y)) * (1 - eps) + eps)\n",
    "    X[:, 1] = Y / X[:, 0]\n",
    "\n",
    "    # Randomly swap x1 and x2\n",
    "    mask = torch.rand(len(Y)) < 0.5\n",
    "    swap_vals = X[:, 0][mask]\n",
    "    X[:, 0][mask] = X[:, 1][mask]\n",
    "    X[:, 1][mask] = swap_vals\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "# Initial generation\n",
    "Y1 = generate_Y(n_samples)\n",
    "X1 = generate_X(Y1, eps)\n",
    "\n",
    "# Ensure they are statistically independent by generating new Y and X values\n",
    "Y2 = generate_Y(n_samples)\n",
    "X2 = generate_X(Y2, eps)\n",
    "\n",
    "# Stack X1 and X2 to get the desired shape\n",
    "X = torch.cat((X1, X2), dim=1)\n",
    "\n",
    "# Stack Y1 and Y2 for the desired shape\n",
    "Y = torch.stack((Y1, Y2), dim=1)\n",
    "\n",
    "# Validate the relationship\n",
    "assert torch.allclose(X[:, 0] * X[:, 1], Y[:, 0])\n",
    "assert torch.allclose(X[:, 2] * X[:, 3], Y[:, 1])\n",
    "\n",
    "# Print the shapes\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(X[:, 0], alpha=0.5, density=True, label=\"mass\")\n",
    "ax.hist(X[:, 1], alpha=0.5, density=True, label=\"acceleration\")\n",
    "ax.hist(Y[:, 0], alpha=0.5, density=True, label=\"force\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(X[:, 2], alpha=0.5, density=True, label=\"mass\")\n",
    "ax.hist(X[:, 3], alpha=0.5, density=True, label=\"acceleration\")\n",
    "ax.hist(Y[:, 1], alpha=0.5, density=True, label=\"force\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, both now look identically distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_inds = np.random.permutation(range(X.shape[0]))  # shuffled indices\n",
    "\n",
    "X_train = X[s_inds[:8000]]\n",
    "Y_train = Y[s_inds[:8000]]\n",
    "X_valid = X[s_inds[8000:]]\n",
    "Y_valid = Y[s_inds[8000:]]\n",
    "\n",
    "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "I'll just do full gradient descent to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000  # number of epochs\n",
    "hidden_dim = 16  # number of hidden units\n",
    "\n",
    "model = Net(input_dim=4, hidden_dim=hidden_dim, output_dim=2)\n",
    "loss_func = nn.MSELoss()\n",
    "optimiser = Adam(model.parameters(), lr=1e-2)\n",
    "log = []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    log_sample = {}\n",
    "\n",
    "    # Training update\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    Y_hat = model(X_train)\n",
    "    loss = loss_func(Y_hat, Y_train)\n",
    "    log_sample[\"train_loss\"] = float(loss.detach())\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    # Validation set\n",
    "    model.eval()\n",
    "    Y_hat = model(X_valid)\n",
    "    loss = loss_func(Y_hat, Y_valid)\n",
    "    log_sample[\"valid_loss\"] = float(loss.detach())\n",
    "\n",
    "    log.append(log_sample)\n",
    "\n",
    "df = pd.DataFrame(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physics_mi.eval import *\n",
    "\n",
    "\n",
    "# need to avoid flattening here because we have multiple outputs\n",
    "def get_preds(model, X_valid, Y_valid):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = model(X_valid)\n",
    "\n",
    "    y_preds = out.numpy()\n",
    "    y_targs = Y_valid.numpy()\n",
    "\n",
    "    return y_preds, y_targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(df[\"train_loss\"], df[\"valid_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_targs = get_preds(model, X_valid, Y_valid)\n",
    "y_preds.shape, y_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valid_loss(model, loss_func, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "plot_results(y_preds[:, 0], y_targs[:, 0], ax=axes[0])\n",
    "plot_results(y_preds[:, 1], y_targs[:, 1], ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both tasks seem to be doing well in parallel ðŸ‘"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physics_mi.analysis import capture_intermediate_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(N=100, vary_task=\"A\"):\n",
    "    pairs = np.concatenate(\n",
    "        np.stack(np.meshgrid(np.linspace(0, 1, N), np.linspace(0, 1, N))).T\n",
    "    )\n",
    "    pairs = torch.tensor(pairs, dtype=torch.float32)\n",
    "    if vary_task == \"A\":\n",
    "        inputs = torch.cat((pairs, torch.full((len(pairs), 2), 0.5)), dim=1)\n",
    "    if vary_task == \"B\":\n",
    "        inputs = torch.cat((torch.full((len(pairs), 2), 0.5), pairs), dim=1)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_inputs = torch.cat(\n",
    "    (get_inputs(100, vary_task=\"A\"), get_inputs(100, vary_task=\"B\"))\n",
    ")\n",
    "task_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ios = capture_intermediate_outputs(model, X_valid)\n",
    "task_ios = capture_intermediate_outputs(model, task_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to compare the principal components at `layers.0.act` with those from `layers.1.act` I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcs(data):\n",
    "    mean = torch.mean(data, 0)\n",
    "    data_centered = data - mean\n",
    "\n",
    "    # Step 2: Compute the SVD\n",
    "    U, S, V = torch.svd(data_centered)\n",
    "\n",
    "    # The columns of V are the principal components\n",
    "    principal_components = V\n",
    "\n",
    "    # Step 3: Compute variances\n",
    "    variances = S.pow(2) / (data.size(0) - 1)\n",
    "\n",
    "    return principal_components, variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_acts0 = task_ios[\"layers.0.act\"]\n",
    "task_acts1 = task_ios[\"layers.1.act\"]\n",
    "task_acts0.shape, task_acts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acts0 = valid_ios[\"layers.0.act\"]\n",
    "valid_acts1 = valid_ios[\"layers.1.act\"]\n",
    "valid_acts0.shape, valid_acts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pcs0, _ = get_pcs(valid_acts0)\n",
    "valid_pcs1, _ = get_pcs(valid_acts1)\n",
    "valid_pcs0.shape, valid_pcs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_acts0 = torch.matmul(valid_pcs0, task_acts0.T).T\n",
    "pc_acts1 = torch.matmul(valid_pcs1, task_acts1.T).T\n",
    "pc_acts0.shape, pc_acts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = torch.cat((pc_acts0, pc_acts1), dim=1)\n",
    "\n",
    "# Compute the covariance matrix of the combined tensor, which will be [32, 32]\n",
    "cov_matrix_full = torch.cov(combined.T)\n",
    "\n",
    "# Extract the [16, 16] covariance matrix between X and Y\n",
    "# This is the top-right or bottom-left quadrant of the full covariance matrix\n",
    "cov_matrix_XY = cov_matrix_full[0:16, 16:32]\n",
    "\n",
    "cross_cov_matrix = cov_matrix_XY.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plotting the heatmap\n",
    "_, ax = plt.subplots(figsize=(10, 8))\n",
    "CM = cross_cov_matrix / np.abs(cross_cov_matrix).max()\n",
    "CM = np.abs(CM)\n",
    "sns.heatmap(CM, annot=True, fmt=\".2f\", cmap=\"bwr\", center=0, ax=ax)\n",
    "ax.set_xlabel(\"Need to work out which layer this is\")\n",
    "ax.set_ylabel(\"Need to work out which layer this is\")\n",
    "_ = ax.set_title(\"Cross-Covariance Matrix Heatmap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physics-mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
